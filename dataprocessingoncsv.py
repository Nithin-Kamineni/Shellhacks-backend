# -*- coding: utf-8 -*-
"""DataProcessingonCSV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FSHBNV36GfkMV_XkOymcIYdm28C7Gkuj
"""

import spacy

nlp = spacy.load("en_core_web_sm")
text = "The image shows a city street scene with tall buildings surrounding the area. There are several cars parked along the street, and a few people can be seen walking or standing on the sidewalks. One person is holding an umbrella, possibly prepared for any weather changes. The street is lined with trees, providing a pleasant atmosphere for the pedestrians and drivers. The view appears to be captured from an elevated point, giving a unique perspective of the cityscape."

corpus = []

doc = nlp(text)
for sent in doc.sents:
    corpus.append(sent.text)

nlp =spacy.blank("en")

ruler = nlp.add_pipe("entity_ruler")

patterns = [
    {"label": "object", "pattern": "person"},
    {"label": "object", "pattern": "car"},
    {"label": "object", "pattern": "cars"},
    {"label": "object", "pattern": "buildings"},
    {"label": "object", "pattern": "people"},
    {"label": "object", "pattern": "pedestrians"},
    {"label": "object", "pattern": "drivers"},
    {"label": "object", "pattern": "trees"},
    {"label": "object", "pattern": "passersby"},
    {"label": "object", "pattern": "viewer"},
    {"label": "object", "pattern": "handbags"},
    {"label": "object", "pattern": "umbrellas"},
    {"label": "quantity", "pattern": "one"},
    {"label": "quantity", "pattern": "several"},
    {"label": "quantity", "pattern": "few"},
    {"label": "quantity", "pattern": "some"},
    {"label": "quantity", "pattern": "many"},
    {"label": "quantity", "pattern": "none"},
    {"label": "quantity", "pattern": "fifty"},
    {"label": "quantity", "pattern": "hundred"},
    {"label": "quantity", "pattern": "plenty"},
    {"label": "quantity", "pattern": "high-rise"},
    {"label": "quantity", "pattern": "11"},
    {"label": "quantity", "pattern": "1"}
]

people ={"person","people","drivers","pedastrains","passerby","viewer"};
cars={"car","cars"};
fobjects=["people","cars","buildings","handbags","umbrellas"];

count={"few":10,"some":10,"one":1,"none":0,"fifty":50,"several":50,"high-rise":75,"many":75,"plenty":75,"hundered":100};
quantity = ["0","1","10","11","50","75","100"]


ruler.add_patterns(patterns)

TRAIN_DATA = []
for sentence in corpus:
    doc = nlp(sentence)
    entities = []

    for ent in doc.ents:
        entities.append([ent.start_char, ent.end_char, ent.text, ent.label_])
    TRAIN_DATA.append([sentence, {"entities": entities}])

# Create a dictionary to map objects to their quantities
object_to_quantity = {}

for data in TRAIN_DATA:
    sentence, annotations = data
    entities = annotations["entities"]
    quantities = filter_entities(entities, ["quantity"])
    objects = filter_entities(entities, ["fobjects"])

    for i, obj in enumerate(fobjects):
        if i < len(quantities):
            quantity = quantities[i]
            if obj not in object_to_quantity:
                object_to_quantity[obj] = int(quantity) if quantity.isnumeric() else count[quantity]
        else:
            # Check if the object is singular or plural and assign "one" or "k" accordingly
            is_plural = obj.endswith("s")
            if is_plural:
                object_to_quantity[obj] = 10
            else:
                object_to_quantity[obj] = 1

object_to_quantity["people"] = sum([object_to_quantity.get(i,0) for i in people])
object_to_quantity["cars"] = sum([object_to_quantity.get(i,0) for i in cars])
# Print the mapping of objects to quantities with specific adjustments
for obj, quantity in object_to_quantity.items():

    print(f"{obj}: {quantity}")

import spacy
import pandas as pd
import os


nlp = spacy.load("en_core_web_sm")

input_csv_file = "/content/ProductionTail.csv"
output_csv_file= "/content/output_ProductionTaildata.csv"

df = pd.read_csv(input_csv_file)


def process_scene_description(description, nlp_model):
    doc = nlp_model(description)
    corpus = []

    for sent in doc.sents:
        corpus.append(sent.text)

    nlp_model = spacy.blank("en")

    ruler = nlp_model.add_pipe("entity_ruler")

    patterns = [
        {"label": "object", "pattern": "person"},
        {"label": "object", "pattern": "car"},
        {"label": "object", "pattern": "cars"},
        {"label": "object", "pattern": "buildings"},
        {"label": "object", "pattern": "people"},
        {"label": "object", "pattern": "pedestrians"},
        {"label": "object", "pattern": "drivers"},
        {"label": "object", "pattern": "trees"},
        {"label": "object", "pattern": "passersby"},
        {"label": "object", "pattern": "viewer"},
        {"label": "object", "pattern": "handbags"},
        {"label": "object", "pattern": "umbrellas"},
        {"label": "quantity", "pattern": "one"},
        {"label": "quantity", "pattern": "several"},
        {"label": "quantity", "pattern": "few"},
        {"label": "quantity", "pattern": "some"},
        {"label": "quantity", "pattern": "many"},
        {"label": "quantity", "pattern": "none"},
        {"label": "quantity", "pattern": "fifty"},
        {"label": "quantity", "pattern": "hundred"},
        {"label": "quantity", "pattern": "plenty"},
        {"label": "quantity", "pattern": "high-rise"},
        {"label": "quantity", "pattern": "11"},
        {"label": "quantity", "pattern": "1"}
    ]

    people = {"person", "people", "drivers", "pedestrians", "passerby", "viewer"}
    cars = {"car", "cars"}
    fobjects = ["people", "cars", "buildings", "handbags", "umbrellas"]

    count = {"few": 10, "some": 10, "one": 1, "none": 0, "fifty": 50, "several": 50, "high-rise": 75, "many": 75, "plenty": 75, "hundred": 100}
    quantity = ["0", "1", "10", "11", "50", "75", "100"]

    ruler.add_patterns(patterns)

    TRAIN_DATA = []
    for sentence in corpus:
        doc = nlp_model(sentence)
        entities = []

        for ent in doc.ents:
            entities.append([ent.start_char, ent.end_char, ent.text, ent.label_])
        TRAIN_DATA.append([sentence, {"entities": entities}])

    # Create a dictionary to map objects to their quantities
    object_to_quantity = {}

    for data in TRAIN_DATA:
        sentence, annotations = data
        entities = annotations["entities"]
        quantities = filter_entities(entities, ["quantity"])
        objects = filter_entities(entities, ["object"])

        for i, obj in enumerate(objects):
            if i < len(quantities):
                quantity = quantities[i]
                if obj in fobjects:
                    if obj not in object_to_quantity:
                        object_to_quantity[obj] = int(quantity) if quantity.isnumeric() else count[quantity]
            else:
                # Check if the object is singular or plural and assign "one" or "k" accordingly
                is_plural = obj.endswith("s")
                if is_plural:
                    object_to_quantity[obj] = 10
                else:
                    object_to_quantity[obj] = 1

    object_to_quantity["people"] = sum([object_to_quantity.get(i, 0) for i in people])
    object_to_quantity["cars"] = sum([object_to_quantity.get(i, 0) for i in cars])

    return object_to_quantity

# Create a list of unique timestamps
timestamps = df["producer_timestamp"].unique()

# Create an empty list to store rows for the output DataFrame
output_rows = []

for timestamp in timestamps:
    timestamp_df = df[df["producer_timestamp"] == timestamp]

    scene_descriptions = timestamp_df["scene_description"]
    item_quantities = {item: 0 for item in fobjects}

    for scene_description in scene_descriptions:
        quantities = process_scene_description(scene_description, nlp)
        for item, quantity in quantities.items():
            if item in fobjects:
                item_quantities[item] += quantity

    # Create a row with timestamp and item quantities
    row = [timestamp] + [item_quantities[item] for item in fobjects]
    output_rows.append(row)

# Create a DataFrame from the list of output rows
output_df = pd.DataFrame(output_rows, columns=["producer_timestamp"] + fobjects)
output_df.to_csv(output_csv_file, index=False)



import pandas as pd

file_path = '/content/ProductionTail.csv'

df = pd.read_csv(file_path, encoding='utf-8')
df['classification'] = df['classification'].str.strip().str.lower()
filtered_data = df.loc[df['classification'] == 'rain', ['producer_timestamp']]
print(filtered_data)

import pandas as pd
from sqlalchemy import create_engine

db_connection_string = "postgresql://username:password@localhost:5432/database_name"


file_path = '/content/output_ProductionTaildata.csv'
df = pd.read_csv(file_path)

df['producer_timestamp'] = pd.to_datetime(df['producer_timestamp'], format='%b %d, %Y @ %H:%M:%S.%f')
df['producer_timestamp'] = df['producer_timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')

engine = create_engine(db_connection_string)
df.to_sql('your_table_name', engine, if_exists='replace', index=False)

engine.dispose()